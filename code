# @title Default title text
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.multioutput import MultiOutputClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score

# Load the dataset
df1 = pd.read_csv('/content/training_set_features.csv')
df2 = pd.read_csv('/content/training_set_labels.csv')
df = pd.concat([df1,df2], axis=0)

# Separate features into numeric and categorical
numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()
categorical_features = df.select_dtypes(include=[object]).columns.tolist()

# Fill missing values for numeric features with median
df[numeric_features] = df[numeric_features].fillna(df[numeric_features].median())

# Fill missing values for categorical features with mode
df[categorical_features] = df[categorical_features].fillna(df[categorical_features].mode().iloc[0])

# Encode categorical variables using one-hot encoding
df = pd.get_dummies(df, columns=[
    'age_group', 'education', 'race', 'sex', 'income_poverty',
    'marital_status', 'rent_or_own', 'employment_status',
    'hhs_geo_region', 'census_msa', 'employment_industry',
    'employment_occupation'], drop_first=True)

# Feature scaling
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df.drop(columns=['respondent_id']))

# Add the respondent_id back after scaling
df_scaled = pd.DataFrame(df_scaled, columns=df.columns.drop('respondent_id'))
df_scaled['respondent_id'] = df['respondent_id'].values

# Exploratory Data Analysis (EDA) - example plot
sns.histplot(df['xyz_concern'])
plt.show()

# Correlation analysis - example heatmap
corr_matrix = df.corr()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.show()

# Create interaction features
df_scaled['concern_knowledge'] = df_scaled['xyz_concern'] * df_scaled['xyz_knowledge']

# Split the data into training and testing sets
X = df_scaled.drop(columns=['xyz_vaccine', 'seasonal_vaccine', 'respondent_id'])
y = df[['xyz_vaccine', 'seasonal_vaccine']]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Random Forest model
model = MultiOutputClassifier(RandomForestClassifier(n_estimators=100, random_state=42))
model.fit(X_train, y_train)

# Predict and evaluate using ROC AUC
y_pred_proba = model.predict_proba(X_test)
y_pred_proba = np.array([proba[:, 1] for proba in y_pred_proba]).T  # Extract probabilities for class 1

roc_auc_xyz = roc_auc_score(y_test['xyz_vaccine'], y_pred_proba[:, 0])
roc_auc_seasonal = roc_auc_score(y_test['seasonal_vaccine'], y_pred_proba[:, 1])
mean_roc_auc = (roc_auc_xyz + roc_auc_seasonal) / 2

print(f'ROC AUC for xyz vaccine: {roc_auc_xyz}')
print(f'ROC AUC for seasonal vaccine: {roc_auc_seasonal}')
print(f'Mean ROC AUC: {mean_roc_auc}')
